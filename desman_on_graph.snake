experiment_name = "g2_r1"

DIR_WITH_SAMPLES = "/Nancy/makseshina/raw_data/ISOLATES_mixes_high_cov/{exp_name}/".format(exp_name=experiment_name)
PROFILE = "/Nancy/makseshina/raw_data/ISOLATES_mixes_high_cov/mix_{exp_name}.csv".format(exp_name=experiment_name)

import pandas as pd
profile_df = pd.read_csv(PROFILE, header=None)
REFS = ["/Nancy/makseshina/raw_data/ISOLATES_mixes/pacbio_refs/s{strain}.fasta".format(strain=strain_name)
                                                                                    for strain_name in profile_df[0]]

FINAL_K = 127
READ_LENGTH = 227

N_SAMPLES = 10
SAMPLES = ["sample"+str(i) for i in range(1,N_SAMPLES+1)]
NAME_OF_LEFT_READ = "s-R1.fastq"
NAME_OF_RIGHT_READ = "s-R2.fastq"


CONTIGS_MIN_LEN = 10000
NUM_SNVs = 3000

REAL_G = len(REFS)

GENOMES_RANGE = range(REAL_G-1+int(REAL_G==2), REAL_G+3)
SEEDS = [0]

SELECTED_G = REAL_G
SELECTED_SEED = 0

LEFT_READS  = expand(DIR_WITH_SAMPLES+"{sample}/"+NAME_OF_LEFT_READ,  sample=SAMPLES)
RIGHT_READS = expand(DIR_WITH_SAMPLES+"{sample}/"+NAME_OF_RIGHT_READ, sample=SAMPLES)

CORRECTED_LEFT_READS  = ["assembly/corrected/s-R1.00.0_%i.cor.fastq.gz" % i for i in range(N_SAMPLES)]
CORRECTED_RIGHT_READS = ["assembly/corrected/s-R2.00.0_%i.cor.fastq.gz" % i for i in range(N_SAMPLES)]


ASSEMBLER_DIR = "~/tools/algorithmic-biology/assembler/bin"
DESMAN_DIR = "/home/makseshina/tools/DESMAN"
PATH_TO_SCRIPTS = "~/meta-strains/scripts/scripts_for_desman"

def is_fastq(read_file_name):
    for ext in {".fastq", ".fq", ".fastq.gz", "fq.gz"}:
        if read_file_name.endswith(ext):
            return True
    return False

#_____________________________________________________________________________


rule all:
    input:
        "edges_analysis.ipynb"
    shell:
        # delete all empty directories
        "find . -type d -empty -delete &"


rule analyse_results:
    input:
        "desman_results/Dev.pdf", "logs/desman_gene_assign/final.log", "logs/sort_all_desman_freqs.log",
        "refs/refs_edges.txt", "refs/profile.csv", "edges_lengths.tsv"
    output:
        "edges_analysis.ipynb"
    shell:
        "cp {PATH_TO_SCRIPTS}/edges_analysis.ipynb {output} && jupyter nbconvert --execute --to notebook --inplace {output}"



rule spades:
    input:   
        LEFT_READS,
        RIGHT_READS
    output:  
        "assembly/contigs.fasta",
        "assembly/K{K}/saves/00_before_repeat_resolution/graph_pack.sqn".format(K=FINAL_K),
        CORRECTED_LEFT_READS,
        CORRECTED_RIGHT_READS,
        "assembly/K{K}/prelim_graph.gfa".format(K=FINAL_K)
    params:  
        left  = " ".join(expand("-1 {r}", r=LEFT_READS)),
        right = " ".join(expand("-2 {r}", r=RIGHT_READS)),
        dir = "assembly/", 
        bh = "" if is_fastq(NAME_OF_LEFT_READ) else "--only-assembler"
    log:     
        "logs/spades.log"
    message: 
        "Assembling all samples together with metaSPAdes"
    shell:   
        "{ASSEMBLER_DIR}/spades.py {params.bh} --meta -t 16 -k 33,55,77,99,127"
        " {params.left} {params.right}"
        " --save-gp -o {params.dir} >{log} 2>&1 "


#____GET_STRAIN_FREQUENCIES_FROM_DESMAN______________________________________

rule cp_long_contigs:
    input:
        "assembly/contigs.fasta"
    output:
        "long_contigs/long_contigs.fa"
    log:
        "logs/cp_long_contigs.log"
    shell:
        "(python {PATH_TO_SCRIPTS}/cp_long_contigs.py {input} {output} {CONTIGS_MIN_LEN}) 2> {log}"


rule bwa_index:
    input:
        "long_contigs/long_contigs.fa"
    output:
        "long_contigs/long_contigs.fa.amb",
        "long_contigs/long_contigs.fa.ann",
        "long_contigs/long_contigs.fa.bwt",
        "long_contigs/long_contigs.fa.pac",
        "long_contigs/long_contigs.fa.sa"
    log:
        "logs/bwa_index.log"
    shell:
        "(bwa index {input}) 2> {log}"


rule bwa_map:
    input:
        contigs = "long_contigs/long_contigs.fa",
        index = lambda wildcards: expand("long_contigs/long_contigs.fa.{ext}",
                ext=["amb", "ann", "bwt", "pac", "sa"]),
        R1 = lambda wildcards: "assembly/corrected/s-R1.00.0_{s}.cor.fastq.gz".format(s=int(wildcards.sample.replace("sample",""))-1),
        R2 = lambda wildcards: "assembly/corrected/s-R2.00.0_{s}.cor.fastq.gz".format(s=int(wildcards.sample.replace("sample",""))-1)
        #R1 = DIR_WITH_SAMPLES + "{sample}/" + NAME_OF_LEFT_READ,
        #R2 = DIR_WITH_SAMPLES + "{sample}/" + NAME_OF_RIGHT_READ
    output:
        temp("mapped_reads/{sample}.bam")
    log:
        "logs/bwa_map/{sample}.log"
    shell:
        "(bwa mem -t 16 {input.contigs} {input.R1} {input.R2}" 
        " | samtools view -bS - > {output}) 2> {log}"


rule samtools_sort:
    input:
        "mapped_reads/{sample}.bam"
    output:
        temp("sorted_reads/{sample}.bam")
    log:
        "logs/samtools_sort/{sample}.log"
    shell:
        "samtools sort -T sorted_reads/{wildcards.sample}"
        " -O bam {input} > {output} 2> {log}"


rule samtools_mpileup:
    input:
        fa = "long_contigs/long_contigs.fa",
        bam = expand("sorted_reads/{sample}.bam", sample=SAMPLES)
    output:
        temp("calls/all.pileup")
    log:
        "logs/samtools_mpileup.log"
    shell:
        "samtools mpileup -A -B -f {input.fa} {input.bam} > {output} 2> {log}"


rule varscan:
    input:
        "calls/all.pileup"
    output:
        "calls/all.varscan"
    log:
        "logs/varscan.log"
    shell:
        "java -jar /home/makseshina/tools/VarScan.v2.3.9.jar mpileup2snp {input} "
        "--min-coverage	10 --min-reads2 5 --min-var-freq 0.02 > {output} 2> {log}"


rule select_sites:
    input:
        "calls/all.varscan"
    output:
        "calls/selected_sites.tsv"
    log:
        "logs/select_sites.log"
    shell:
        "python {PATH_TO_SCRIPTS}/filter_SNVs.py "
        "{input} {output} {NUM_SNVs} 2> {log}"


rule bam_readcount:
    input:
        sites_list = "calls/selected_sites.tsv",
        fasta = "long_contigs/long_contigs.fa",
        bam_file = "sorted_reads/{sample}.bam"
    output:
        temp("counts/{sample}.cnt")
    log:
        "logs/bam_readcount/{sample}.log"
    shell:
        "samtools index {input.bam_file} {input.bam_file}.bai; "
        "bam-readcount -l {input.sites_list} -f {input.fasta} {input.bam_file} 2> {log} > {output}; "
        "rm {input.bam_file}.bai"


rule extract_counts:
    input:
        all_counts = lambda wildcards: expand("counts/{sample}.cnt", \
                                              sample=SAMPLES)
    output:
        "desman_input/freqs.csv"
    params:
        input_dir = "counts"
    log:
        "logs/extract_counts.log"
    shell:
        "python {PATH_TO_SCRIPTS}/extract_counts.py "
        "{params.input_dir} {output} 2> {log}"


rule desman_variant_filter:
    input:
        "desman_input/freqs.csv"
    output:
        expand("desman_input/filtered_{output_file_type}",
                output_file_type = ["sel_var.csv", "p_df.csv", "q_df.csv", "r_df.csv", "tran_df.csv", "log.txt"])
    shell:
        "python {DESMAN_DIR}/desman/Variant_Filter.py --output_stub desman_input/filtered_ {input}"


rule run_desman:
    input:
        sel_var = "desman_input/freqs.csv",
    output:
        desman_results = expand("desman_results/{{g}}_{{r}}/{file_type}",
                                file_type = ["log_file.txt", "fit.txt", "Gamma_star.csv", "Eta_star.csv"])
    log:
        "logs/desman_results/{g}_{r}.log"
    params:
        desman_python2_env = "desman_2"
    run:
        output_dir = os.path.dirname(output.desman_results[0])
	shell("set +u; source activate {params.desman_python2_env}; set -u;"
        " desman {input.sel_var} -o {output_dir} -i 100 -g {wildcards.g} -s {wildcards.r} > {log}")


rule run_all_desman:
    input: lambda wildcards: expand("desman_results/{g}_{r}/fit.txt", \
            g = GENOMES_RANGE, \
            r = SEEDS)
    output: 
        "desman_results/Dev.csv"
    shell:
        "cat <(echo 'H,G,LP,Dev') <(cat {input} | cut -d',' -f2-) > {output}"


rule plot_dev:
    input: 
        "desman_results/Dev.csv"
    output: 
        "desman_results/Dev.pdf"
    shell:
        "{DESMAN_DIR}/scripts/PlotDev.R -l {input} -o {output}"


#____ASSIGN_EDGES_TO_DIFFERENT_STRAINS_BY_DESMAN_________________________________________


rule gen_dataset_yaml:
    input:
        CORRECTED_LEFT_READS,
        CORRECTED_RIGHT_READS
    output:
        "input_dataset.yaml"
    log:
        "logs/gen_dataset_yaml.log"
    shell:
        "python {PATH_TO_SCRIPTS}/gen_dataset_yaml.py {N_SAMPLES} {input}  > {output}"


rule count_edges_kmer_cov:
    input:
        contigs = "assembly/contigs.fasta",
	yaml = "input_dataset.yaml"
    output:
        "desman_input/edge_profiles.txt"
    log:
        "logs/count_edges_kmer_cov.log"
    shell:
        "(~/tools/algorithmic-biology_sydney/assembler/build/release/bin/strain_mix_from_graph -k {FINAL_K}"
        " -g assembly/K{FINAL_K}/saves/00_before_repeat_resolution/graph_pack -d {input.yaml} -p {output} -t 8) 2> {log}"


rule count_edges_read_cov:
    input:
        profile = "desman_input/edge_profiles.txt"
    params:
        sample_names = ",".join(SAMPLES)
    output:
        "desman_input/edge_profiles.read_cov.txt"
    shell:
        "python ~/meta-strains/scripts/to_read_cov.py {input.profile} {output} {params.sample_names} -k {FINAL_K} -r {READ_LENGTH}"


rule make_mean_sd_df:
    input:
        "desman_input/freqs.csv"
    output:
        "desman_input/mean_sd_df.csv"
    shell:
        "python ~/meta-strains/scripts/make_mean_sd_df.py {input} {output}"


rule desman_gene_assign:
    input:
        mean_sd_df = "desman_input/mean_sd_df.csv",
        gamma_star = "desman_results/{g}_{r}/Gamma_star.csv",
        edge_profiles = "desman_input/edge_profiles.read_cov.txt",
        eta_star = "desman_results/{g}_{r}/Eta_star.csv",
        snv_freqs = "desman_input/freqs.csv"
    output:
        "desman_results/{g}_{r}/gene_assignment_etaS_df.csv"
    log:
        "logs/desman_gene_assign/{g}_{r}.log"
    params:
        desman_python2_env = "desman_2",
        output_prefix = "desman_results/{g}_{r}/gene_assignment_"
    shell:
        "set +u; source activate {params.desman_python2_env}; set -u;"
        " python {DESMAN_DIR}/desman/GeneAssign.py"
        " {input.mean_sd_df} {input.gamma_star} {input.edge_profiles} {input.eta_star} -v {input.snv_freqs}"
        " -o {params.output_prefix} --assign_tau > {log}"


rule run_all_gene_assign:
    input: lambda wildcards: expand("desman_results/{g}_{r}/gene_assignment_etaS_df.csv", \
            g = GENOMES_RANGE, \
            r = SEEDS)
    output:
        "logs/desman_gene_assign/final.log"
    shell:
        "echo All works were done > {output}"



#____VALIDATE_DESMAN_RESULTS_____________________________________________________________


rule sort_desman_freqs:
    input:
        "desman_results/{g}_{r}/Gamma_star.csv"
    output:
        "desman_results/{g}_{r}/desman_freqs.csv"
    shell:
        "python {PATH_TO_SCRIPTS}/sort_desman_freqs.py {input} {output}"


rule sort_all_desman_freqs:
    input:
        expand("desman_results/{g}_{r}/desman_freqs.csv", g=GENOMES_RANGE, r=SEEDS)
    output:
        "logs/sort_all_desman_freqs.log"
    shell:
        "echo All works were done > {output}"


rule concat_refs:
    input:
        REFS
    output:
        "refs/all_refs.fasta"
    shell:
        "python {PATH_TO_SCRIPTS}/concat_refs.py {output} {input}"


rule thread_refs:
    input:
        refs = "refs/all_refs.fasta",
        assembly_flag = "assembly/contigs.fasta"
    output:
        edges = "refs/refs_edges.txt",
        paths = "refs/refs_paths.txt"
    log:
        "logs/thread_refs.log"
    shell:
        "(~/tools/algorithmic-biology_sydney/assembler/build/release/bin/sequence_threader -k {FINAL_K}"
        " -g assembly/K{FINAL_K}/saves/00_before_repeat_resolution/graph_pack -q {input.refs}"
        " -p {output.paths} -e {output.edges}) > {log}"


rule copy_profile:
    input:
        PROFILE
    output:
        "refs/profile.csv"
    shell:
        "cp {input} {output}"


rule count_edges_length:
    input:
        "assembly/K{K}/prelim_graph.gfa".format(K=FINAL_K)
        #"assembly/K{K}/saves/00_before_repeat_resolution/graph_pack.sqn".format(K=FINAL_K)
    output:
        "edges_lengths.tsv"
    shell:
        "python {PATH_TO_SCRIPTS}/edges_lengths.py {input} {output}"
